In questa sezione vengono messi a confronto 4 modelli da 8 miliardi di parametri quantizzati in Q4_K_M

- LLAMA 3.1
- QWEN 2.5
- MISTRAL
- GEMMA2

Per analizzare le interazioni tra i modelli nei vari use case utilizzate i seguenti link; alla fine di ogni interazione potete trovare il mio commento in ROSSO con il mio voto al lavoro svolto dal modello, gli errori trovati nelle traduzioni vengono evidenziti da >>>{ERROR}<<< per visualizzarli facilmente effettuate una ricerca nella pagina (ctrl+f) di ">>>":

- [Domanda scentifica oneshoot](https://it-alian.github.io/4LLM/8B%20CHALLENGE/oneshoot_llm_interaction.htm)
- [Traduzione di un testo](https://it-alian.github.io/4LLM/8B%20CHALLENGE/translate_llm_interaction.htm)
- [Riassunto di un testo](https://it-alian.github.io/4LLM/8B%20CHALLENGE/summary_llm_interaction.htm)
- [Problema di coding](https://it-alian.github.io/4LLM/8B%20CHALLENGE/coding_llm_interaction.htm)

Analizzando i risultati si puo vedere come questi modelli a 8B siano piuttosto limitati commettano molti errori nei loro task. Anche se possono essere un valido supporto di lavoro devono attentamente essere controllati e verificati. 
Di seguito il video delle interazioni con il vincitore stile "4 Ristoranti"

https://www.youtube.com/watch?v=dI3CTy1mKAA
